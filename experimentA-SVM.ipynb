{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. EFFECT OF THE NUMBER OF TRAINING SAMPLES ON PERFORMANCE\n",
    "In this experiment, we will evaluate the effect of proposed few-shot learning method to address the first two challenges in limited data fault diagnosis: 1) industry systems are not allowed to run into faulty states due to the consequences, especially for critical systems and failures; 2) most electromechanical failures occur slowly and follow a degradation path such that failure degradation of a system might take months or even years. We conducted a series of experiments on the training data in datasets D with 90, 120, 300, 900, 1500, 3000, 6000, 12000, 19800 samples respectively, then evaluated the effect of numbers on performance for each training model. We repeated each experiment ten times to deal with the randomness of the algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "# set the memory usage\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=tf_config))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import imp\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets/CWRU 12DriveEndFault 1730\n",
      "0 Datasets/CWRU/NormalBaseline/1730/Normal.mat\n",
      "(485643, 2)\n",
      "1 Datasets/CWRU/NormalBaseline/1750/Normal.mat\n",
      "dict_keys(['X099_FE_time', 'ans', '__header__', 'X098_DE_time', '__globals__', '__version__', 'X099_DE_time', 'X098_FE_time'])\n",
      "(485063, 2)\n",
      "2 Datasets/CWRU/NormalBaseline/1772/Normal.mat\n",
      "(483903, 2)\n",
      "3 Datasets/CWRU/12DriveEndFault/1730/0.007-Ball.mat\n",
      "(121556, 2)\n",
      "4 Datasets/CWRU/12DriveEndFault/1750/0.007-Ball.mat\n",
      "(121556, 2)\n",
      "5 Datasets/CWRU/12DriveEndFault/1772/0.007-Ball.mat\n",
      "(121410, 2)\n",
      "6 Datasets/CWRU/12DriveEndFault/1730/0.014-Ball.mat\n",
      "(122136, 2)\n",
      "7 Datasets/CWRU/12DriveEndFault/1750/0.014-Ball.mat\n",
      "(121991, 2)\n",
      "8 Datasets/CWRU/12DriveEndFault/1772/0.014-Ball.mat\n",
      "(122136, 2)\n",
      "9 Datasets/CWRU/12DriveEndFault/1730/0.021-Ball.mat\n",
      "(122136, 2)\n",
      "10 Datasets/CWRU/12DriveEndFault/1750/0.021-Ball.mat\n",
      "(122136, 2)\n",
      "11 Datasets/CWRU/12DriveEndFault/1772/0.021-Ball.mat\n",
      "(121701, 2)\n",
      "12 Datasets/CWRU/12DriveEndFault/1730/0.007-InnerRace.mat\n",
      "(122917, 2)\n",
      "13 Datasets/CWRU/12DriveEndFault/1750/0.007-InnerRace.mat\n",
      "(122136, 2)\n",
      "14 Datasets/CWRU/12DriveEndFault/1772/0.007-InnerRace.mat\n",
      "(121991, 2)\n",
      "15 Datasets/CWRU/12DriveEndFault/1730/0.014-InnerRace.mat\n",
      "(121701, 2)\n",
      "16 Datasets/CWRU/12DriveEndFault/1750/0.014-InnerRace.mat\n",
      "(121846, 2)\n",
      "17 Datasets/CWRU/12DriveEndFault/1772/0.014-InnerRace.mat\n",
      "(121846, 2)\n",
      "18 Datasets/CWRU/12DriveEndFault/1730/0.021-InnerRace.mat\n",
      "(121991, 2)\n",
      "19 Datasets/CWRU/12DriveEndFault/1750/0.021-InnerRace.mat\n",
      "(121846, 2)\n",
      "20 Datasets/CWRU/12DriveEndFault/1772/0.021-InnerRace.mat\n",
      "(121556, 2)\n",
      "21 Datasets/CWRU/12DriveEndFault/1730/0.007-OuterRace6.mat\n",
      "(122571, 2)\n",
      "22 Datasets/CWRU/12DriveEndFault/1750/0.007-OuterRace6.mat\n",
      "(121410, 2)\n",
      "23 Datasets/CWRU/12DriveEndFault/1772/0.007-OuterRace6.mat\n",
      "(122426, 2)\n",
      "24 Datasets/CWRU/12DriveEndFault/1730/0.014-OuterRace6.mat\n",
      "(121991, 2)\n",
      "25 Datasets/CWRU/12DriveEndFault/1750/0.014-OuterRace6.mat\n",
      "(121846, 2)\n",
      "26 Datasets/CWRU/12DriveEndFault/1772/0.014-OuterRace6.mat\n",
      "(122136, 2)\n",
      "27 Datasets/CWRU/12DriveEndFault/1730/0.021-OuterRace6.mat\n",
      "(121991, 2)\n",
      "28 Datasets/CWRU/12DriveEndFault/1750/0.021-OuterRace6.mat\n",
      "(122281, 2)\n",
      "29 Datasets/CWRU/12DriveEndFault/1772/0.021-OuterRace6.mat\n",
      "(121991, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " [('NormalBaselineNormal', 0),\n",
       "  ('12DriveEndFault0.007-Ball', 1),\n",
       "  ('12DriveEndFault0.014-Ball', 2),\n",
       "  ('12DriveEndFault0.021-Ball', 3),\n",
       "  ('12DriveEndFault0.007-InnerRace', 4),\n",
       "  ('12DriveEndFault0.014-InnerRace', 5),\n",
       "  ('12DriveEndFault0.021-InnerRace', 6),\n",
       "  ('12DriveEndFault0.007-OuterRace6', 7),\n",
       "  ('12DriveEndFault0.014-OuterRace6', 8),\n",
       "  ('12DriveEndFault0.021-OuterRace6', 9)],\n",
       " 19800,\n",
       " 750)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cwru \n",
    "\n",
    "window_size = 2048\n",
    "data = cwru.CWRU(['12DriveEndFault'], ['1772', '1750', '1730'], window_size)\n",
    "data.nclasses,data.classes,len(data.X_train),len(data.X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import siamese\n",
    "# imp.reload(siamese)\n",
    "import utils\n",
    "imp.reload(utils)\n",
    "\n",
    "\n",
    "settings = {}\n",
    "\n",
    "exp_name = \"EXP-AB\"\n",
    "exps = [60,90,120,200,300,600,900,1500,3000,6000,12000,19800]\n",
    "times = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "def EXPAB_train_and_test(exp_name,exps,is_training):\n",
    "    train_classes = sorted(list(set(data.y_train)))\n",
    "    train_indices = [np.where(data.y_train == i)[0] for i in train_classes]\n",
    "    for exp in exps:\n",
    "        scores_svm = []\n",
    "        num = int(exp/len(train_classes))\n",
    "        for time_idx in range(times):\n",
    "            seed = time_idx*10\n",
    "            np.random.seed(seed)\n",
    "            print(\"\\n%s-%s\"%(exp,time_idx) + '*'*80)\n",
    "            settings[\"save_path\"] = \"tmp/%s/size_%s/time_%s/\" % (exp_name,exp,time_idx)\n",
    "            data._mkdir(settings[\"save_path\"])\n",
    "\n",
    "            train_idxs = []\n",
    "            val_idxs = []\n",
    "            for i, c in enumerate(train_classes):\n",
    "                select_idx = train_indices[i][np.random.choice(len(train_indices[i]), num, replace=False)]\n",
    "                split = int(0.6*num)\n",
    "                train_idxs.extend(select_idx[:split])\n",
    "                val_idxs.extend(select_idx[split:])\n",
    "            X_train, y_train = data.X_train[train_idxs],data.y_train[train_idxs], \n",
    "            X_val, y_val = data.X_train[val_idxs],data.y_train[val_idxs], \n",
    "            \n",
    "            X_train = np.concatenate((X_train, X_val), axis=0)\n",
    "            y_train = np.concatenate((y_train, y_val), axis=0)\n",
    "            \n",
    "            clf = svm.SVC(gamma='scale', decision_function_shape='ovo')\n",
    "#             print(X_train.shape)\n",
    "            clf.fit(X_train.reshape(len(X_train),-1), y_train)\n",
    "\n",
    "            pred = clf.predict(data.X_test.reshape(len(data.X_test),-1))\n",
    "            score = accuracy_score(data.y_test,pred)*100\n",
    "            print('svm:',score)\n",
    "            scores_svm.append(score)\n",
    "            \n",
    "            if time_idx%10==0:\n",
    "                utils.confusion_plot(pred,data.y_test)\n",
    "                \n",
    "\n",
    "        a =pd.DataFrame(np.array(scores_svm))\n",
    "        a.to_csv(\"tmp/%s/size_%s/scores_svm.csv\" % (exp_name,exp),index=True)  \n",
    "\n",
    "        \n",
    "EXPAB_train_and_test(exp_name,exps,is_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                     0\n",
       " model exp             \n",
       " SVM   60     18.933333\n",
       "       90     26.560000\n",
       "       120    31.200000\n",
       "       200    38.666667\n",
       "       300    43.893333\n",
       "       600    50.053333\n",
       "       900    52.346667\n",
       "       1500   54.533333\n",
       "       6000   63.360000\n",
       "       19800  72.933333,                     0\n",
       " model exp            \n",
       " SVM   60     1.523155\n",
       "       90     2.354004\n",
       "       120    0.889444\n",
       "       200    2.351359\n",
       "       300    1.564609\n",
       "       600    2.232288\n",
       "       900    1.994660\n",
       "       1500   1.002220\n",
       "       6000   1.241504\n",
       "       19800  0.000000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps = [60,90,120,200,300,600,900,1500,6000,19800]\n",
    "scores_svm_all = pd.DataFrame()\n",
    "for exp in exps:\n",
    "    file_path = \"tmp/%s/size_%s\" % (exp_name,exp)\n",
    "    tmp_data = pd.read_csv(\"%s/scores_svm.csv\" % (file_path), \n",
    "                           sep=',', index_col=0)\n",
    "    tmp_data['exp'] = exp \n",
    "    scores_svm_all = pd.concat([scores_svm_all,tmp_data],axis=0)\n",
    "\n",
    "\n",
    "scores_svm_all.to_csv(\"tmp/%s/scores_svm_all.csv\" % (exp_name), float_format='%.6f', index=True)\n",
    "\n",
    "\n",
    "scores_svm_all['model'] = 'SVM'\n",
    "\n",
    "scores_all = scores_svm_all\n",
    "\n",
    "scores_all_mean = scores_all.groupby(['model','exp']).mean()\n",
    "scores_all_std = scores_all.groupby(['model','exp']).std()\n",
    "scores_all_mean.to_csv(\"tmp/%s/scores_svm_mean.csv\" % (exp_name), float_format='%.2f', index=True)\n",
    "scores_all_std.to_csv(\"tmp/%s/scores_svm_std.csv\" % (exp_name), float_format='%.2f', index=True)\n",
    "scores_all_mean, scores_all_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
